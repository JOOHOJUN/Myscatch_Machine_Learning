{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "조엘 그루스, 2016, 인사이트, '밑바닥부터 시작하는 데이터 과학'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 깁슨 샘플링 : 일부 조건부 확률을 알고 있을 때의 샘플링 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math, random, re\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def roll_a_die():\n",
    "    return random.choice([1,2,3,4,5,6])\n",
    "\n",
    "#보통의 표본생성\n",
    "def direct_sample():\n",
    "    d1 = roll_a_die()\n",
    "    d2 = roll_a_die()\n",
    "    return d1, d1 + d2\n",
    "\n",
    "#조건부 확률분포만 안다고 가정했을 때\n",
    "# 두 개의 주사위 중 하나의 주사위 값(x)을 알고 그 합을 도출할 때, x를 알면 y값의 경우의 수를 알 수 있다.\n",
    "def random_y_given_x(x):\n",
    "    return x + roll_a_die()\n",
    "#두 개의 주사위 합을 알 때 두 개의 주사위의 값의 경우의 수를 알 수 있다.\n",
    "def random_x_given_y(y):\n",
    "    if y<= 7:\n",
    "        return random.randrange(1, y)\n",
    "    else:\n",
    "        return random.randrange(y - 6, 7)\n",
    "random_x_given_y(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gibbs_sample(num_iters =100):\n",
    "    x, y = 1, 2 # x와 y를 초기화\n",
    "    for _ in range(num_iters):\n",
    "        x = random_x_given_y(y)\n",
    "        y = random_y_given_x(x)\n",
    "    return x, y\n",
    "gibbs_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서별 단어리스트\n",
    "# documents[3][4] => 4번째 문서의 5번째 단어\n",
    "documents = [\n",
    "    [\"Hadoop\", \"Big Data\", \"HBase\", \"Java\", \"Spark\", \"Storm\", \"Cassandra\"],\n",
    "    [\"NoSQL\", \"MongoDB\", \"Cassandra\", \"HBase\", \"Postgres\"],\n",
    "    [\"Python\", \"scikit-learn\", \"scipy\", \"numpy\", \"statsmodels\", \"pandas\"],\n",
    "    [\"R\", \"Python\", \"statistics\", \"regression\", \"probability\"],\n",
    "    [\"machine learning\", \"regression\", \"decision trees\", \"libsvm\"],\n",
    "    [\"Python\", \"R\", \"Java\", \"C++\", \"Haskell\", \"programming languages\"],\n",
    "    [\"statistics\", \"probability\", \"mathematics\", \"theory\"],\n",
    "    [\"machine learning\", \"scikit-learn\", \"Mahout\", \"neural networks\"],\n",
    "    [\"neural networks\", \"deep learning\", \"Big Data\", \"artificial intelligence\"],\n",
    "    [\"Hadoop\", \"Java\", \"MapReduce\", \"Big Data\"],\n",
    "    [\"statistics\", \"R\", \"statsmodels\"],\n",
    "    [\"C++\", \"deep learning\", \"artificial intelligence\", \"probability\"],\n",
    "    [\"pandas\", \"R\", \"Python\"],\n",
    "    [\"databases\", \"HBase\", \"Postgres\", \"MySQL\", \"MongoDB\"],\n",
    "    [\"libsvm\", \"regression\", \"support vector machines\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4개의 토픽을 뽑아보자\n",
    "K =4\n",
    "document_topic_counts = [Counter() for _ in documents] #각 토픽이 각 문서에 할당되는 횟수\n",
    "topic_word_counts = [Counter() for _ in range(K)]      #각 단어가 각 토픽에 할당되는 횟수\n",
    "topic_counts = [0 for _ in range(K)]                   #각 토픽에 할당되는 총 단어 수\n",
    "document_lengths = list(map(len, documents))           #각 문서에 포함되는 총 단어 수 \n",
    "distinct_words = set(word for document in documents for word in document)\n",
    "W = len(distinct_words) #단어 종류의 수 \n",
    "D = len(documents) #총 문서의 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 변수 간략 설명<br>\n",
    "document_topic_counts\n",
    "i번째 문서 중에서 토픽 j와 관련있는 단어의 수\n",
    "\n",
    ">document_topic_counts[i][j]\n",
    "\n",
    "test라는 단어가 토픽 j와 연관지어 나오는 횟수\n",
    "\n",
    ">topic_word_counts[j]['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d번째 문서의 총 단어 중 topic에 해당하는 단어의 비율(smoothing추가 : 0 이상의 확률을 가지도록함)\n",
    "def p_topic_given_document(topic, d, alpha =0.1):\n",
    "    return ((document_topic_counts[d][topic] + alpha) / (document_lengths[d] + K*alpha))\n",
    "# topic에 속한 단어들 중 word의 비율(smoothing추가 : 0 이상의 확률을 가지도록함)\n",
    "def p_word_given_topic(word, topic, beta=0.1):\n",
    "    return ((topic_word_counts[topic][word] + beta) / (topic_counts[topic] + W*beta))\n",
    "\n",
    "#가중치 업데이트\n",
    "def topic_weight(d, word, k):\n",
    "    return p_word_given_topic(word, k) * p_topic_given_document(k, d)\n",
    "#가중치를 이용해 어느정도 랜덤적으로 토픽을 반환\n",
    "def sample_from(weights):\n",
    "    total = sum(weights)\n",
    "    rnd = total * random.random()\n",
    "    for i, w in enumerate(weights):\n",
    "        rnd -= w\n",
    "        if rnd <= 0: return i\n",
    "#새로운 토픽 반환\n",
    "def choose_new_topic(d, word):\n",
    "    return sample_from([topic_weight(d, word, k) for k in range(K)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "document_topics = [[random.randrange(K) for word in document] for document in documents]\n",
    "\n",
    "# 임의로 할당 -> 초기화\n",
    "for d in range(D):\n",
    "    for word, topic in zip(documents[d], document_topics[d]):\n",
    "        document_topic_counts[d][topic] += 1\n",
    "        topic_word_counts[topic][word] += 1\n",
    "        topic_counts[topic] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in range(1000):\n",
    "    for d in range(D):\n",
    "        for i, (word, topic) in enumerate(zip(documents[d], document_topics[d])):\n",
    "            #단어와 단어에 할당된 토픽을 지운다.\n",
    "            document_topic_counts[d][topic] -= 1\n",
    "            topic_word_counts[topic][word] -= 1\n",
    "            topic_counts[topic] -= 1\n",
    "            document_lengths[d] -= 1\n",
    "            \n",
    "            #weight를 이용해 새로운 값 도출\n",
    "            new_topic = choose_new_topic(d, word)\n",
    "            document_topics[d][i] = new_topic\n",
    "            \n",
    "            #새로운 값을 다시 할당한다.\n",
    "            document_topic_counts[d][new_topic] += 1\n",
    "            topic_word_counts[new_topic][word] += 1\n",
    "            topic_counts[new_topic] += 1\n",
    "            document_lengths[d] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter({3: 0, 0: 7, 2: 0, 1: 0}),\n",
       " Counter({3: 0, 2: 0, 1: 5, 0: 0}),\n",
       " Counter({1: 2, 0: 0, 2: 2, 3: 2})]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_topic_counts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Java</td>\n",
       "      <td>HBase</td>\n",
       "      <td>regression</td>\n",
       "      <td>statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>neural networks</td>\n",
       "      <td>R</td>\n",
       "      <td>probability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hadoop</td>\n",
       "      <td>Postgres</td>\n",
       "      <td>libsvm</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HBase</td>\n",
       "      <td>MongoDB</td>\n",
       "      <td>scikit-learn</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C++</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>Python</td>\n",
       "      <td>pandas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Spark</td>\n",
       "      <td>Cassandra</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>statsmodels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Storm</td>\n",
       "      <td>numpy</td>\n",
       "      <td>support vector machines</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>programming languages</td>\n",
       "      <td>decision trees</td>\n",
       "      <td>Haskell</td>\n",
       "      <td>artificial intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MapReduce</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>Mahout</td>\n",
       "      <td>theory</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0                 1                        2  \\\n",
       "0                   Java             HBase               regression   \n",
       "1               Big Data   neural networks                        R   \n",
       "2                 Hadoop          Postgres                   libsvm   \n",
       "3                  HBase           MongoDB             scikit-learn   \n",
       "4                    C++  machine learning                   Python   \n",
       "5                  Spark         Cassandra              mathematics   \n",
       "6                  Storm             numpy  support vector machines   \n",
       "7  programming languages    decision trees                  Haskell   \n",
       "8              MapReduce     deep learning                   Mahout   \n",
       "\n",
       "                         3  \n",
       "0               statistics  \n",
       "1              probability  \n",
       "2                   Python  \n",
       "3                        R  \n",
       "4                   pandas  \n",
       "5              statsmodels  \n",
       "6                      C++  \n",
       "7  artificial intelligence  \n",
       "8                   theory  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#시각화"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
